# EasyDS - 基于多智能体的智能教学系统

## 1. 系统概述

EasyDS 是一个基于大语言模型的多智能体协同教学系统，初期专注于数据结构教育。系统采用费曼学习法的教学理念，通过学生智能体、用户交互和教师智能体的三方协作完成教学过程。

### 1.1 核心特点

- 基于图结构的多智能体系统
- 动态提示词生成算法（RLHF）
- 知识图谱驱动的问题生成
- 交互式教学体验

## 2. 系统架构
```
EasyDS/
|—— functional_docs/
|   ├── main_plans.md      # 主计划文档
|   ├── data_processing.md # 数据处理文档
|   ├── system_integration.md # 系统集成文档
|—— data/
│   ├── preference_data/   # DPO训练数据
│   │   ├── raw_data.jsonl
│   │   ├── train_data.jsonl
│   │   ├── eval_data.jsonl
│   │   └── test_data.jsonl
│   ├── rlhf_data/        # RLHF训练数据
│   │   ├── sft/          # SFT阶段数据
│   │   │   ├── sft_raw_data.jsonl
│   │   │   ├── sft_train_data.jsonl
│   │   │   └── sft_eval_data.jsonl
│   │   └── ppo/          # PPO阶段数据
│   │       ├── ppo_raw_data.jsonl
│   │       ├── ppo_train_data.jsonl
│   │       └── ppo_eval_data.jsonl
├── src/
│   ├── data/
│   │   ├── __init__.py
│   │   ├── processor.py
│   │   ├── converter.py
│   │   └── augmenter.py
│   ├── training/
│   │   ├── __init__.py
│   │   ├── dpo/          # DPO相关实现
│   │   │   ├── trainer.py
│   │   │   └── utils.py
│   │   └── rlhf/         # RLHF相关实现
│   │       ├── sft_trainer.py
│   │       ├── ppo_trainer.py
│   │       ├── reward_model.py
│   │       └── utils.py
│   └── utils/
│       ├── __init__.py
│       └── common.py
├── configs/
│   ├── dpo_config.yaml   # DPO配置
│   └── rlhf/             # RLHF配置
│       ├── sft_config.yaml
│       └── ppo_config.yaml
└── scripts/
    ├── processing_data.py
    ├── train_dpo.py      # DPO训练脚本
    └── train_rlhf/       # RLHF训练脚本
        ├── train_sft.py
        └── train_ppo.py
```

### 2.1 智能体组成

1. **学生智能体**
   - 基于知识图谱生成学习问题
   - 模拟真实学生的提问行为
   - 问题难度动态调整

2. **教师智能体**
   - 评估用户回答质量
   - 提供个性化教学引导
   - 使用动态生成的提示词优化响应

3. **用户交互模块**
   - 接收学生智能体的问题
   - 处理用户的回答输入
   - 展示教师智能体的反馈

### 2.2 核心模块

1. **动态提示词生成系统**
   - RLHF训练框架
   - 奖励模型设计
   - 提示词优化算法

2. **知识图谱系统**
   - 数据结构知识体系构建
   - 知识点关联关系定义
   - 学习路径规划

3. **多智能体协同框架**
   - 基于LangGraph的智能体通信
   - 会话状态管理
   - 智能体角色定义

## 3. 实现计划

### 3.1 第一阶段：动态提示词生成系统

1. **数据准备**
   - 收集教学对话数据集
   - 构建偏好数据对（preferred/rejected responses）
   - 设计评估标准

2. **DPO模型训练**
   - 实现DPO训练框架
   - 训练提示词生成器
   - 模型评估和优化

3. **对比实验设计**
   - 基准测试
     * 使用相同的基础模型
     * 准备相同规模的训练数据
     * 统一评估环境和计算资源

   - 实验环境准备
     * DPO训练环境配置
     * RLHF训练环境配置
     * 数据预处理流程
     * 评估环境搭建

   - 训练过程对比
     * DPO单阶段训练
     * RLHF多阶段训练（SFT+PPO）
     * 训练参数配置
     * 中间结果记录

   - 资源消耗对比
     * GPU使用情况
     * 内存占用
     * 存储需求
     * 训练时长

   - 效果评估
     * 提示词质量评分
     * 教学相关性评估
     * 人工评估反馈
     * 自动评估指标（困惑度、ROUGE等）

   - 实用性分析
     * 部署难度
     * 维护成本
     * 迭代效率
     * 系统稳定性

4. **实验数据收集**
   - 构建评估数据集
     * 简单问题样本
     * 复杂问题样本
     * 边界情况测试
   
   - 数据准备策略
     * DPO偏好数据构建
     * RLHF奖励建模数据
     * 验证数据集划分
     * 测试数据准备

5. **结果分析**
   - 优势对比
     * DPO vs RLHF性能差异
     * 场景适用性分析
     * 成本效益分析
   
   - 改进建议
     * 模型优化方向
     * 数据质量提升
     * 训练策略调整

### 3.2 第二阶段：多智能体系统

1. **基础框架搭建**
   - LangGraph环境配置
   - 智能体通信协议设计
   - 会话流程实现

2. **智能体开发**
   - 学生智能体实现
   - 教师智能体集成
   - 用户交互模块开发

3. **知识图谱构建**
   - 数据结构知识体系整理
   - 图谱关系定义
   - 知识点难度划分

### 3.3 第三阶段：系统集成

1. **模块整合**
   - 动态提示词系统接入
   - 知识图谱系统集成
   - 智能体协同调试

2. **系统优化**
   - 性能优化
   - 用户体验改进
   - 教学效果评估

## 4. 技术栈

- LangGraph: 多智能体框架
- PyTorch: DPO模型训练
- Neo4j: 知识图谱存储
- FastAPI: 后端服务
- Vue.js: 前端界面

## 5. 评估指标

1. **教学效果**
   - 学习者理解度
   - 知识点掌握程度
   - 学习积极性

2. **系统性能**
   - 响应时间
   - 资源占用
   - 系统稳定性

3. **用户体验**
   - 交互流畅度
   - 引导准确性
   - 反馈及时性

## 6. 后续扩展

1. **课程扩展**
   - 添加更多计算机科学课程
   - 支持跨学科知识关联

2. **功能增强**
   - 个性化学习路径
   - 学习进度追踪
   - 协作学习支持
