{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import sys\n",
    "sys.path.append(\"/root/autodl-tmp/EasyDS\")\n",
    "\n",
    "# from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from pydantic import BaseModel, Field, ConfigDict, field_validator\n",
    "from typing import Annotated, List, Optional, Dict, Any, Literal, TypedDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatDeepSeek(model=\"deepseek-chat\", openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"))\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\", openai_api_key=api_key, openai_api_base='https://api.deepseek.com', temperature=0.9, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 智能体间的通讯状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "    messages: Annotated[List[AnyMessage], add_messages] = Field(default_factory=list, title=\"对话列表\")\n",
    "    question: list = Field(default=[], title=\"当前题目信息\")\n",
    "    evaluation: dict = Field(default={}, title=\"用户回复评估\")\n",
    "    log: str = Field(default=\"\", title=\"节点执行日志\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router Agent\n",
    "\n",
    "接收历史对话信息以及最新的用户回复进行路由选择\n",
    "\n",
    "- 如果用户回复内容错误\n",
    "    - 直接转向 Teacher Agent\n",
    "\n",
    "- 如果用户回复内容正确\n",
    "    - 回复错误，转向 Teacher Agent 进行纠正\n",
    "    - 回复正确且完整，转向 Teacher Agent 进行总结\n",
    "    - 回复正确，但是不完整，转向 Student Agent 进行追问\n",
    "    - 回复不完整，转向 Student Agent 进行进一步的追问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(TypedDict):\n",
    "    is_right: bool = Field(default=None, title=\"用户回复是否正确\")\n",
    "    is_complete: bool = Field(default=None, title=\"用户回复是否完整\")\n",
    "    reason: str = Field(default=\"\", title=\"用户回复评估原因\")\n",
    "    next_agent: Literal[\"teacher\", \"student\"]\n",
    "    \n",
    "\n",
    "async def router_agent(state: State, config) -> Command[Literal[\"teacher_agent\", \"student_agent\"]]:\n",
    "    \"\"\"根据当前状态进行路由\"\"\"\n",
    "    try:\n",
    "        curr_question = state.question[0]\n",
    "        with open(\"/root/autodl-tmp/EasyDS/src/agents/prompts/router_agent_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            prompt = f.read()\n",
    "        prompt = ChatPromptTemplate([\n",
    "            (\"system\", prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\")\n",
    "        ])\n",
    "        system_prompt = prompt.partial(title=curr_question['title'],content=curr_question['content'],answer=curr_question['reference_answer']['content'],explanation=curr_question['reference_answer']['explanation'])\n",
    "        chain = system_prompt | llm.with_structured_output(Evaluation, method=\"function_calling\")\n",
    "        router_result = await chain.ainvoke({\"messages\": state.messages}, config)\n",
    "        if router_result['next_agent'] == 'teacher':\n",
    "            goto = \"teacher_agent\"\n",
    "        else:\n",
    "            goto = \"student_agent\"\n",
    "        return Command(\n",
    "            update={\n",
    "                \"evaluation\": router_result,\n",
    "            },\n",
    "            goto=goto\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return Command(\n",
    "            update={\n",
    "                \"log\": str(e)\n",
    "            },\n",
    "            goto=\"teacher_agent\"                           \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Agent\n",
    "\n",
    "根据从 Router Agent 转来的状态进行回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def student_agent(state: State, config) -> State:\n",
    "    try:\n",
    "        curr_question = state.question[0]\n",
    "        evaluation = state.evaluation\n",
    "        with open(\"/root/autodl-tmp/EasyDS/src/agents/prompts/student_agent_prompt2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            prompt = f.read()\n",
    "        prompt = ChatPromptTemplate([\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{messages}\")\n",
    "        ])\n",
    "        system_prompt = prompt.partial(\n",
    "            title=curr_question['title'],\n",
    "            content=curr_question['content'],\n",
    "            answer=curr_question['reference_answer']['content'],\n",
    "            explanation=curr_question['reference_answer']['explanation'],\n",
    "            is_right=evaluation['is_right'],\n",
    "            is_complete=evaluation['is_complete'],\n",
    "            reason=evaluation['reason']\n",
    "        )\n",
    "        chain = system_prompt | llm\n",
    "        stu_feedback = await chain.ainvoke({\"messages\": state.messages}, config)\n",
    "        return {\"messages\": stu_feedback}\n",
    "    except Exception as e:\n",
    "        return {\"log\": str(e)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Agent\n",
    "\n",
    "根据从路由智能体转来的状态进行回复\n",
    "\n",
    "- 如果 is_right == False，即用户回答错误，teacher_agent 进行错误分类与讲解建议\n",
    "- 如果 is_right == True，进行总结\n",
    "- 如果 is_right == None, 回答用户问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.ds_data.data_processing.index_builder import KnowledgeIndexSystem\n",
    "\n",
    "async def knowledge_summry_search(knowledge_points: list):\n",
    "    \"\"\"根据知识点列表查询知识点概述\"\"\"\n",
    "    try:\n",
    "        system = await KnowledgeIndexSystem.load_indices_async('/root/autodl-tmp/EasyDS/data/ds_data/ds_indices.pkl')\n",
    "        knowledge_summry = []\n",
    "        for kp in knowledge_points:\n",
    "            knowledge_point_info = await system.get_knowledge_point_async(kp)\n",
    "            if knowledge_point_info:    \n",
    "                knowledge_summry.append({\n",
    "                    \"knowledge_point\": knowledge_point_info['title'],\n",
    "                    \"summry\": knowledge_point_info['summry']\n",
    "                })\n",
    "        if knowledge_summry:\n",
    "            # 将知识点的概述进行拼接\n",
    "            knowledge_summry_str = \"\\n\".join([f\"{kp['knowledge_point']}: {kp['summry']}\" for kp in knowledge_summry])\n",
    "            return knowledge_summry_str\n",
    "        else:\n",
    "            return \"未找到对应知识点\"\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "tools = [knowledge_summry_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def teacher_agent(state: State, config) -> Command[Literal[\"tool_node\", \"__end__\"]]:\n",
    "    \"\"\"根据当前状态进行回复\"\"\"\n",
    "    try:\n",
    "        curr_question = state.question[0]\n",
    "        evaluation = state.evaluation\n",
    "        with open(\"/root/autodl-tmp/EasyDS/src/agents/prompts/teacher_agent_prompt.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            prompt = f.read()\n",
    "        prompt = ChatPromptTemplate([\n",
    "            (\"system\", prompt),\n",
    "            (\"human\", \"{messages}\")\n",
    "        ])\n",
    "        system_prompt = prompt.partial(\n",
    "            title=curr_question['title'],\n",
    "            content=curr_question['content'],\n",
    "            answer=curr_question['reference_answer']['content'],\n",
    "            knowledge_points=curr_question['knowledge_points'],\n",
    "            explanation=curr_question['reference_answer']['explanation'],\n",
    "            is_right=evaluation['is_right'],\n",
    "            is_complete=evaluation['is_complete'],\n",
    "            reason=evaluation['reason']\n",
    "        )\n",
    "        chain = system_prompt | llm.bind_tools(tools)\n",
    "        teacher_feedback = await chain.ainvoke({\"messages\": state.messages}, config)\n",
    "        if teacher_feedback.tool_calls:\n",
    "            goto = \"tool_node\"\n",
    "        else:\n",
    "            goto = \"__end__\"\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": teacher_feedback\n",
    "            },\n",
    "            goto=goto\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return Command(\n",
    "            update={\n",
    "                \"log\": str(e)\n",
    "            },\n",
    "            goto=\"__end__\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MainGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"router_agent\", router_agent)\n",
    "workflow.add_node(\"student_agent\", student_agent)\n",
    "workflow.add_node(\"teacher_agent\", teacher_agent)\n",
    "workflow.add_node(\"tool_node\", ToolNode(tools))\n",
    "workflow.add_edge(START, \"router_agent\")\n",
    "workflow.add_edge(\"tool_node\", \"teacher_agent\")\n",
    "workflow.add_edge(\"student_agent\", \"__end__\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = workflow.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Setting xray to 1 will show the internal structure of the nested graph\n",
    "display(Image(graph.get_graph(xray=2).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = KnowledgeIndexSystem.load_indices('/root/autodl-tmp/EasyDS/data/ds_data/ds_indices.pkl')\n",
    "question = system.get_question(\"q011002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid4())}}\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"A\")],\n",
    "    \"question\": [question],\n",
    "    \"evaluation\": {},\n",
    "    \"log\": \"\"\n",
    "}\n",
    "async for msg, metadata in graph.astream(inputs, config, stream_mode=\"messages\"):\n",
    "    print(msg.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid4())}}\n",
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"线性结构是一对一的关系，而树是1对多的关系，所以是非线性结构\")],\n",
    "    \"question\": [question],\n",
    "    \"evaluation\": {},\n",
    "    \"log\": \"\"\n",
    "}\n",
    "async for msg, metadata in graph.astream(inputs, config, stream_mode=\"messages\"):\n",
    "    print(msg.content, end=\"|\")\n",
    "    print(metadata['langgraph_node'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easyDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
